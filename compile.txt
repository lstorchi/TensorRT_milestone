***** MINIMAL COMPILE ******

g++ testingTRT.cpp -o testingTRT -std=c++11 -Wl,--start-group -lnvinfer -lnvparsers -lnvinfer_plugin -lcudnn -lcublas -lcudart_static -lnvToolsExt -lcudart -lrt -ldl -lpthread -Wl,--end-group



***** IF READING FROM HDF5 FILE *****

g++ testingTRT.cpp -o testingTRT -std=c++11 -Wl,--start-group -lnvinfer -lnvparsers -lnvinfer_plugin -lcudnn -lcublas -lcudart_static -lnvToolsExt -lcudart -lrt -ldl -lpthread -Wl,--end-group -lhdf5_cpp -lhdf5


****** TO CONVERT A FROZEN MODEL TO A UFF MODEL (IMPORTED IN TENSORRT) ******

convert-to-uff tensorflow -o name_of_output_uff_file --input-file name_of_input_pb_file -O name_of_output_tensor



_________________________________________________________________________

**** INCLUDED IN THE .sh FILE (ENVIRONMENT VARIABLE: LIBRARY_PATH) ****

-L/data/user/adipilat/inferenceGPU/venv/mycuda/lib64 -L/data/user/adipilat/inferenceGPU/venv/TensorRT-4.0.1.6/lib


**** INCLUDED IN THE .sh FILE (ENVIRONMENT VARIABLE: CPLUS_INCLUDE_PATH) ****

-I/data/user/adipilat/inferenceGPU/venv/TensorRT-4.0.1.6/samples/common -I/data/user/adipilat/inferenceGPU/venv/TensorRT-4.0.1.6/include


******OUT (NOT USED) *****

-I/usr/local/include
-I/data/user/adipilat/inferenceGPU/venv/mycuda/include

-L/usr/local/lib
-L/data/user/adipilat/inferenceGPU/venv/mycuda/targets/x86_64-linux/lib64


